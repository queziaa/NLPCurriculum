
预测层。解码器生成上下文化的标签表示，这些表示被投影到最终的|𝑉 |-维向量上，其中|𝑉 |是标签词汇表的大小。结果向量的每个元素代表相应标签的概率。预测层由一个全连接层和一个Softmax激活函数组成。
损失函数。遵循原始变换器架构，我们使用Kullback-Leibler散度损失，它衡量两个概率分布之间的不相似性。在训练期间，我们使用值𝜖𝑙𝑠 = 0.2 [27]的标签平滑。标签平滑是一种正则化技术，涉及将目标标签的独热编码替换为平滑分布。标签平滑不是给真实标签分配概率1，而是给其他所有标签分配概率0，而是给真实标签分配一个信心分数，并在其他标签中重新分配平滑质量。在HECTOR中，在损失函数中引入了一些关于标签分类法的先验知识。由于我们的目标是解码树路径而不是非结构化序列，我们提前知道每个位置可以出现哪些标签。因此，在第𝑖个位置，只有分类法中深度为𝑖的层级上的标签可能出现。我们通过应用掩码到标签上来利用这一知识，使平滑质量在相应的层级上重新分配，将所有其他标签的概率设置为0。我们将在第4.3节讨论这种方法的影响。
训练。在多标签问题中，每个文档可以有来自不同（子）领域的标签，结果在标签树中形成多个路径。在训练期间，我们随机选择每个文档的一个路径作为每个训练时期的真实输出。这种方法背后的思想是在训练中引入一些变化性，避免过度拟合特定的输出序列——与[32]的观察一致。通过在训练期间随机选择一个可能的输出路径作为真实输出，模型学会以相同的概率生成所有可能的输出路径。

使用HECTOR进行标签补全 在推理过程中，HECTOR接收包含已知标签的路径前缀。我们使用波束搜索为每个数据点生成多个路径并预测缺失标签。与贪婪搜索不同，贪婪搜索在每一步选择概率最高的候选者，波束搜索维护一组最有前途的候选序列，称为波束。具体来说，算法如下进行：
• 模型为位置𝑖生成一组候选标签。
• 选择概率最高的前𝑘个候选者，其中𝑘是波束宽度。
• 将选定的候选者附加到前面的部分序列（从位置1到𝑖−1的预测标签）上，并计算扩展序列的联合概率。
将前𝑘个扩展序列传递到下一步，为位置𝑖+1生成一组候选标签。






数据集
我们在三个著名的大规模数据集上评估我们的方法：MAG-CS、PubMed 和 EURLex。
• MAG-CS：Microsoft Academic Graph (MAG) 计算机科学 (CS) 是 MAG 数据集的一个子集，专注于计算机科学领域，包含从 1990 年到 2020 年在 105 个顶级 CS 会议上发表的论文，而标签树包含“计算机科学”根级别的相关概念的后代。
• PubMed：我们使用 [36] 发布的 PubMed 子集，其中包括从 2010 年到 2020 年在 150 个顶级医学期刊上发表的论文。每篇 PubMed 论文都用医学主题词表 (MeSH) 中的相关概念进行标注。
• EURLex：EURLex [18] 是最常见的 XMLC 基准数据集之一。它包含来自 EUR-LEX 门户的英文欧盟立法文件，并用欧洲词汇表 (EuroVoc) 中的概念（标签）进行标注。我们使用 在 2019 年发布的最新版本的 EURLex。
我们进一步扩展了每个数据点的标签集，使它们构成树中的完整路径，如第 3.2 节所述。我们在表 1 中报告了数据集的重要统计数据，图 3 总结了 3 个数据集中每个级别的标签分布。
 
 


实验
这个项目是从头训练一个Transformer，encoder300维 decoder600维 均为6层 12个头 ，encoder 序列长300 ，decoder长16，一万条数据 100轮，时间约17小时。

 
实验结构和论文中给出的一致

评价指标的计算方式如下，rank根据正确率返回1 or 0
 